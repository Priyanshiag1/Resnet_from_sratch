# ğŸ§  ResNet From Scratch â€“ CIFAR-10 Classification

This project implements **Residual Networks (ResNet)** entirely from scratch using **TensorFlow/Keras**, and applies them to the CIFAR-10 image classification task. A custom-built ResNet-18 architecture is used to balance **performance and training time**, achieving strong classification results and insightful predictions.

---

## ğŸš€ Highlights

- âœ… Implemented **ResNet blocks and full ResNet architecture** from scratch.
- âœ… Trained on the **CIFAR-10 dataset** (32x32 RGB images).
- âœ… Compared different ResNet depths: **ResNet-18, 34, 50**.
- âœ… Visualized **Top-5 class predictions** with confidence bars.
- âœ… Final version uses **ResNet-18** for optimal trade-off between accuracy and training time.

---

## ğŸ—ï¸ ResNet Architecture

Implemented components:
- ğŸ”¹ Convolutional Blocks with BatchNorm + ReLU
- ğŸ”¹ Identity and Projection Shortcuts
- ğŸ”¹ Residual Block Builder Function
- ğŸ”¹ Final Fully Connected Classifier

Supported architectures:
- `ResNet-18` âœ… (used in final model)
- `ResNet-34`, `ResNet-50` (tested, slower, high memory)

---

## ğŸ§ª Model Performance

| Metric                | Score     |
|-----------------------|-----------|
| âœ… Training Accuracy   | **95.15%** |
| âœ… Validation Accuracy | **89.82%** |
| âœ… Top-5 Accuracy      | **99.64%** |

- Optimizer: `Adam`
- Loss: `SparseCategoricalCrossentropy`
- EarlyStopping + ModelCheckpoint used

---

## ğŸ“Š Top-5 Class Predictions Demo

Images can be uploaded for prediction using the trained ResNet model. The model displays top-5 labels with confidence bars for each image.

## ğŸ§  Why ResNet-18?

While ResNet-50 and deeper models perform better in theory, on CIFAR-10 they led to:
- âš ï¸ **High computation time**
- âš ï¸ **Overfitting**
- âš ï¸ **GPU memory issues (on Colab)**

Hence, **ResNet-18** was chosen for:
- âš¡ Faster training
- ğŸ”„ Balanced depth
- ğŸ§  Sufficient representation for CIFAR-10

---
